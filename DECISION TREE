from collections import Counter
import numpy as np

class DecisionNode:
    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):
        self.feature = feature
        self.threshold = threshold
        self.left = left
        self.right = right
        self.value = value

class DecisionTree:
    def __init__(self):
        self.tree = None

    def fit(self, X, y):
        self.tree = self.build_tree(X, y)

    def build_tree(self, X, y):
        if len(set(y)) == 1:
            return DecisionNode(value=y[0])

        best_feature, best_threshold = self.find_best_split(X, y)
        if best_feature is None:
            return DecisionNode(value=Counter(y).most_common(1)[0][0])

        left_indices = X[:, best_feature] < best_threshold
        right_indices = ~left_indices

        left_tree = self.build_tree(X[left_indices], y[left_indices])
        right_tree = self.build_tree(X[right_indices], y[right_indices])

        return DecisionNode(feature=best_feature, threshold=best_threshold, left=left_tree, right=right_tree)

    def find_best_split(self, X, y):
        best_gini = 1
        best_feature = None
        best_threshold = None

        for feature in range(X.shape[1]):
            thresholds = np.unique(X[:, feature])
            for threshold in thresholds:
                left_indices = X[:, feature] < threshold
                gini = self.calculate_gini(y[left_indices], y[~left_indices])
                if gini < best_gini:
                    best_gini = gini
                    best_feature = feature
                    best_threshold = threshold

        return best_feature, best_threshold

    def calculate_gini(self, left_labels, right_labels):
        p_left = len(left_labels) / (len(left_labels) + len(right_labels))
        p_right = len(right_labels) / (len(left_labels) + len(right_labels))
        gini_left = 1 - sum((Counter(left_labels).get(label, 0) / len(left_labels)) ** 2 for label in set(left_labels))
        gini_right = 1 - sum((Counter(right_labels).get(label, 0) / len(right_labels)) ** 2 for label in set(right_labels))
        gini = p_left * gini_left + p_right * gini_right
        return gini

    def predict(self, X):
        return np.array([self._predict(x, self.tree) for x in X])

    def _predict(self, x, tree):
        if tree.value is not None:
            return tree.value
        if x[tree.feature] < tree.threshold:
            return self._predict(x, tree.left)
        else:
            return self._predict(x, tree.right)

if __name__ == "__main__":
    # Example dataset
    X = np.array([[2, 5], [3, 6], [4, 8], [5, 3], [6, 4]])
    y = np.array([0, 0, 1, 1, 1])

    # Create and fit the decision tree model
    model = DecisionTree()
    model.fit(X, y)

    # Make predictions
    print("Predictions:", model.predict(X))
